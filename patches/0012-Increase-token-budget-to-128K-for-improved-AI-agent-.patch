From 8bb688523287fa729df9ab68eeeec49328a1a9cb Mon Sep 17 00:00:00 2001
From: Den <2119348+dzianisv@users.noreply.github.com>
Date: Tue, 22 Jul 2025 18:34:07 +0300
Subject: [PATCH 12/91] Increase token budget to 128K for improved AI agent
 capabilities

- Update maxTokens default from 1000 to 128000 in background.js
- Update maxTokens default from 100000 to 128000 in ai_agent.js
- Allows complex tasks to complete without token budget exhaustion
---
 chrome/browser/resources/vibe/ai_agent.js   | 358 +++++++++++++++-----
 chrome/browser/resources/vibe/background.js |   9 +-
 2 files changed, 279 insertions(+), 88 deletions(-)

diff --git a/chrome/browser/resources/vibe/ai_agent.js b/chrome/browser/resources/vibe/ai_agent.js
index cdbd64d95a..de834af187 100644
--- a/chrome/browser/resources/vibe/ai_agent.js
+++ b/chrome/browser/resources/vibe/ai_agent.js
@@ -4,7 +4,6 @@
 // Browser Automation AI Agent using LangChain
 
 import { initChatModel } from "langchain/chat_models/universal";
-import { ChatPromptTemplate, MessagesPlaceholder } from "@langchain/core/prompts";
 import { HumanMessage, AIMessage, SystemMessage, ToolMessage } from "@langchain/core/messages";
 import { ConversationSummaryBufferMemory } from "langchain/memory";
 import { browserTools as extensionBrowserTools } from "./ai_tools.extension.js";
@@ -27,6 +26,120 @@ export class VibeLangchainAgent {
     this.memory = null; // Will be initialized when model is available
   }
 
+  /**
+   * Process a user request with the AI agent
+   * @param {Object} params
+   * @param {string} params.user_request
+   * @param {string} params.tabId
+   * @param {AgentConfig} [params.config]
+   * @param {Array<any>} [params.agent_scratchpad]
+   * @returns {Promise<any>}
+   */
+  // Track content extraction failures to trigger screenshot fallback
+  #contentExtractionFailures = 0;
+  #lastScreenshotTime = 0;
+  #MAX_CONTENT_FAILURES_BEFORE_SCREENSHOT = 2;
+  #MIN_SCREENSHOT_INTERVAL_MS = 5000; // 5 seconds between screenshots
+
+  /**
+   * Try to get page content with automatic fallback to screenshot if needed
+   * @private
+   */
+  /**
+   * Validates that a string is a safe data URL for screenshots
+   * @private
+   */
+  #isValidScreenshotDataUrl(url) {
+    return typeof url === 'string' && 
+           url.startsWith('data:image/jpeg;base64,') && 
+           url.length > 100; // Basic length check to ensure it's a real image
+  }
+
+  /**
+   * Formats a screenshot for use in a multimodal message
+   * @private
+   */
+  #formatScreenshotForMultimodal(screenshotDataUrl) {
+    if (!this.#isValidScreenshotDataUrl(screenshotDataUrl)) {
+      console.warn('[AI_AGENT] Invalid screenshot data URL format');
+      return null;
+    }
+    
+    return {
+      type: 'image_url',
+      image_url: {
+        url: screenshotDataUrl,
+        detail: 'high' // Can be 'low', 'high', or 'auto' - using 'high' for maximum detail
+      }
+    };
+  }
+
+  /**
+   * Try to get page content with automatic fallback to screenshot if needed
+   * @private
+   */
+  async #getPageContentWithFallback(tabId, attempt = 0) {
+    try {
+      const pageContentTool = this.tools.find(t => t.name === 'get_page_content');
+      if (!pageContentTool) {
+        throw new Error('get_page_content tool not found');
+      }
+
+      const content = await pageContentTool.call({ tabId });
+      this.#contentExtractionFailures = 0; // Reset failure counter on success
+      return { content, usedScreenshot: false };
+    } catch (error) {
+      console.warn(`[AI_AGENT] Content extraction failed (attempt ${attempt + 1}):`, error);
+      this.#contentExtractionFailures++;
+
+      // Take screenshot if we've failed too many times or if we haven't taken one recently
+      const now = Date.now();
+      const shouldTakeScreenshot = this.#contentExtractionFailures >= this.#MAX_CONTENT_FAILURES_BEFORE_SCREENSHOT &&
+                                (now - this.#lastScreenshotTime) > this.#MIN_SCREENSHOT_INTERVAL_MS;
+
+      if (shouldTakeScreenshot) {
+        try {
+          const screenshotTool = this.tools.find(t => t.name === 'take_screenshot');
+          if (screenshotTool) {
+            console.log('[AI_AGENT] Falling back to screenshot due to content extraction failures');
+            this.#lastScreenshotTime = now;
+            const screenshot = await screenshotTool.call({ tabId });
+            
+            // Format the screenshot as a multimodal message part
+            const screenshotMessage = this.#formatScreenshotForMultimodal(screenshot);
+            
+            if (screenshotMessage) {
+              return { 
+                content: [
+                  {
+                    type: 'text',
+                    text: 'Screenshot taken due to content extraction failure:'
+                  },
+                  screenshotMessage
+                ],
+                usedScreenshot: true 
+              };
+            }
+          }
+        } catch (screenshotError) {
+          console.error('[AI_AGENT] Screenshot fallback failed:', screenshotError);
+        }
+      }
+
+      // If we're not taking a screenshot or it failed, rethrow the original error
+      if (attempt < 1) {
+        // Retry once before giving up
+        return this.#getPageContentWithFallback(tabId, attempt + 1);
+      }
+      
+      // If we get here, all fallbacks have failed
+      return { 
+        content: 'Failed to extract page content or take a screenshot. The page may be loading or have restricted access.',
+        usedScreenshot: false 
+      };
+    }
+  }
+
   /**
    * Process a user request with the AI agent
    * @param {Object} params
@@ -45,6 +158,41 @@ export class VibeLangchainAgent {
     const tools = config.tools || this.tools;
     const langchainTools = tools.map(toolInstance => toolInstance.toLangChainTool());
 
+    // Wrap content extraction tools with our fallback logic
+    const originalToolCall = this.toolCall ? this.toolCall.bind(this) : null;
+    this.toolCall = async (toolCall) => {
+      // Intercept content extraction tool calls
+      if (toolCall.name === 'get_page_content' || toolCall.name === 'get_dom_structure') {
+        try {
+          const { content, usedScreenshot } = await this.#getPageContentWithFallback(toolCall.args.tabId || tabId);
+          
+          // If we used a screenshot, also log it as a tool observation
+          if (usedScreenshot) {
+            return {
+              tool_call_id: toolCall.tool_call_id,
+              output: content,
+              screenshot_used: true
+            };
+          }
+          
+          return {
+            tool_call_id: toolCall.tool_call_id,
+            output: content
+          };
+        } catch (error) {
+          console.error('[AI_AGENT] Content extraction with fallback failed:', error);
+          throw error;
+        }
+      }
+      
+      // For other tools, use the original implementation or throw error
+      if (originalToolCall) {
+        return originalToolCall(toolCall);
+      } else {
+        throw new Error(`Tool not implemented: ${toolCall.name}`);
+      }
+    };
+
     // Model selection and API key resolution
     // Handle both old (apiKey) and new (apiKeys) config formats
     const provider = config.provider || 'openai';
@@ -107,10 +255,44 @@ export class VibeLangchainAgent {
     console.log(`üîß [AI_AGENT] Model config:`, { 
       modelName, 
       hasApiKey: !!modelConfig.apiKey,
-      hasBaseURL: !!modelConfig.baseURL 
+      hasBaseURL: !!modelConfig.baseURL
     });
 
-    const llm = await initChatModel(modelName, modelConfig);
+    console.log(`üöÄ [AI_AGENT] Attempting to initialize model: ${modelName}`);
+    let llm;
+    try {
+      llm = await initChatModel(modelName, modelConfig);
+      console.log(`üì± [AI_AGENT] initChatModel returned:`, {
+        type: typeof llm,
+        isNull: llm === null,
+        isUndefined: llm === undefined,
+        hasBindMethod: llm && typeof llm.bind === 'function'
+      });
+    } catch (initError) {
+      console.error(`‚ùå [AI_AGENT] initChatModel failed:`, initError);
+      throw new Error(`Model initialization failed: ${initError.message}`);
+    }
+
+    // Check if LLM initialization was successful
+    if (!llm) {
+      throw new Error(`initChatModel returned null/undefined for model ${modelName}. Please check your API key and model configuration.`);
+    }
+    
+    if (typeof llm.bind !== 'function') {
+      console.error(`‚ùå [AI_AGENT] LLM object details:`, {
+        type: typeof llm,
+        constructor: llm.constructor?.name,
+        methods: llm ? Object.getOwnPropertyNames(llm).filter(prop => typeof llm[prop] === 'function') : [],
+        hasBindMethod: 'bind' in llm,
+        bindType: typeof llm.bind
+      });
+      throw new Error(`Model ${modelName} was initialized but doesn't have a bind method. Object type: ${typeof llm}, constructor: ${llm.constructor?.name}`);
+    }
+
+    console.log(`‚úÖ [AI_AGENT] Successfully initialized model: ${modelName}`);
+
+    // Bind tools to the model for function calling using LangChain v0.3 API
+    const llmWithTools = llm.bindTools(langchainTools);
 
     // Initialize LangChain memory with intelligent summarization
     if (!this.memory) {
@@ -123,39 +305,36 @@ export class VibeLangchainAgent {
       console.log(`üß† [AI_AGENT] Initialized LangChain memory with ${this.memory.maxTokenLimit} token limit`);
     }
 
-    // Bind tools to the model for function calling
-    const llmWithTools = llm.bind({ tools: langchainTools });
-
-    // Optimized system prompt - reduced from ~430 to ~150 tokens
-    const ROUTING_RULES = "flights.google.com, booking.com, amazon.com for flights/hotels/shopping";
-    const WORKFLOW_PATTERN = "reasoning ‚Üí get_page_content ‚Üí act ‚Üí verify ‚Üí finish_task";
+    // Enhanced system prompt with detailed flight booking workflow
+    const FLIGHT_SITES = "https://flights.google.com, https://www.expedia.com, https://www.kayak.com";
+    const WORKFLOW_PATTERN = "reasoning ‚Üí navigate_to_url ‚Üí get_page_content ‚Üí fill_form ‚Üí get_page_content ‚Üí select_dropdown ‚Üí continue";
     
-    const systemPrompt = `Browser automation agent. Tab: ${tabId}
+    const systemPrompt = `Flight booking specialist. Tab: ${tabId}
 
-**Workflow:** ${WORKFLOW_PATTERN}
-**Rules:** Always use get_page_content before interactions. Never guess selectors. Use ${ROUTING_RULES}.
-**Tools:** ${langchainTools.map(t => t.name).join(', ')}
+**CRITICAL WORKFLOW FOR FLIGHTS:**
+1. User requests flight booking ‚Üí IMMEDIATELY navigate to ${FLIGHT_SITES}  
+2. After navigation ‚Üí get_page_content to see the page
+3. Fill departure airport ‚Üí get_page_content to see dropdown suggestions
+4. Click dropdown suggestion ‚Üí get_page_content to confirm
+5. Fill destination airport ‚Üí get_page_content to see dropdown suggestions  
+6. Click dropdown suggestion ‚Üí continue with dates
+7. ALWAYS call get_page_content AFTER each form interaction to see dynamic changes
 
-Example first call:
-{"tool_calls":[{"name":"reasoning","args":{"thinking":"I need to...","next_goal":"..."}}]}`;
+**DYNAMIC CONTENT RULE**: Airport inputs show dropdown suggestions when typing. You MUST:
+- Type "SFO" ‚Üí get_page_content ‚Üí click suggestion from dropdown
+- Type "JFK" ‚Üí get_page_content ‚Üí click suggestion from dropdown
 
-    // Get conversation history from LangChain memory and add current request
-    const chatHistory = await this.memory.chatHistory.getMessages();
-    const messages = [
-      new SystemMessage(systemPrompt),
-      ...chatHistory,
-      new HumanMessage(user_request)
-    ];
-    
-    // Add the current user message to memory
-    await this.memory.chatHistory.addMessage(new HumanMessage(user_request));
+**Tools:** ${langchainTools.map(t => t.name).join(', ')}
+
+START WITH: navigate_to_url to https://flights.google.com`;
 
     const maxIterations = config.maxIterations || 32;
-    const maxTokens = config.maxTokens || 100000; // Token budget guard
+    const maxTokens = config.maxTokens || 128000; // Token budget guard
     const deadlineMs = config.timeoutMs ? Date.now() + config.timeoutMs : null; // Timeout guard
     const toolResults = [];
     let consecutiveFailures = 0;
     let totalTokensUsed = 0;
+    let currentUserMessage = user_request; // Track current user input for memory
     
     // Retry function with exponential backoff
     const retryWithBackoff = async (fn, maxRetries = 3, baseDelay = 1000) => {
@@ -172,34 +351,43 @@ Example first call:
       }
     };
     
-    for (let iteration = 1; iteration <= maxIterations; iteration++) {
-      // Check budget and timeout guards
-      if (deadlineMs && Date.now() > deadlineMs) {
-        console.log(`‚è∞ [AI_AGENT] Timeout reached after ${iteration-1} iterations`);
-        return {
-          output: `Task incomplete - timeout reached after ${iteration-1} iterations`,
-          reasoning: "Operation timed out before completion",
-          toolResults,
-          iterations: iteration-1,
-          completed: false,
-          reason: 'timeout'
-        };
-      }
+    try {
+      for (let iteration = 1; iteration <= maxIterations; iteration++) {
+        // Build fresh messages from memory each iteration to prevent unbounded growth
+        const { chat_history = [] } = await this.memory.loadMemoryVariables({});
+        const messages = [
+          new SystemMessage(systemPrompt),
+          ...chat_history,
+          new HumanMessage(currentUserMessage)
+        ];
+        
+        // Check budget and timeout guards
+        if (deadlineMs && Date.now() > deadlineMs) {
+          console.log(`‚è∞ [AI_AGENT] Timeout reached after ${iteration-1} iterations`);
+          return {
+            output: `Task incomplete - timeout reached after ${iteration-1} iterations`,
+            reasoning: "Operation timed out before completion",
+            toolResults,
+            iterations: iteration-1,
+            completed: false,
+            reason: 'timeout'
+          };
+        }
 
-      if (totalTokensUsed > maxTokens) {
-        console.log(`üí∞ [AI_AGENT] Token budget exceeded: ${totalTokensUsed}/${maxTokens}`);
-        return {
-          output: `Task incomplete - token budget exceeded (${totalTokensUsed}/${maxTokens})`,
-          reasoning: "Token budget exhausted before completion", 
-          toolResults,
-          iterations: iteration-1,
-          completed: false,
-          reason: 'budget_exceeded'
-        };
-      }
+        if (totalTokensUsed > maxTokens) {
+          console.log(`üí∞ [AI_AGENT] Token budget exceeded: ${totalTokensUsed}/${maxTokens}`);
+          return {
+            output: `Task incomplete - token budget exceeded (${totalTokensUsed}/${maxTokens})`,
+            reasoning: "Token budget exhausted before completion", 
+            toolResults,
+            iterations: iteration-1,
+            completed: false,
+            reason: 'budget_exceeded'
+          };
+        }
 
-      try {
-        const result = await llmWithTools.invoke(messages);
+        try {
+          const result = await llmWithTools.invoke(messages);
         
         // Track token usage if available
         if (result.response_metadata?.tokenUsage?.totalTokens) {
@@ -224,18 +412,11 @@ Example first call:
             };
           }
           
-          // Add AI message to conversation with properly formatted tool_calls
-          const formattedToolCalls = result.tool_calls.map(toolCall => ({
-            id: toolCall.id,
-            type: 'function',
-            function: {
-              name: toolCall.name,
-              arguments: JSON.stringify(toolCall.args)
-            }
-          }));
-          const aiMessage = new AIMessage(result.content, { tool_calls: formattedToolCalls });
-          messages.push(aiMessage);
-          await this.memory.chatHistory.addMessage(aiMessage);
+          // Add AI response to memory using v0.3 API with correct input/output
+          await this.memory.saveContext(
+            { input: currentUserMessage },
+            { output: result.content }
+          );
           
           // Execute each tool call
           for (const toolCall of result.tool_calls) {
@@ -246,7 +427,6 @@ Example first call:
               const errorMsg = `Tool not found: ${toolCall.name}`;
               const errorToolMessage = new ToolMessage(errorMsg, toolCall.id, toolCall.name);
               messages.push(errorToolMessage);
-              await this.memory.chatHistory.addMessage(errorToolMessage);
               continue;
             }
 
@@ -289,11 +469,11 @@ Example first call:
                 result: toolResult
               });
               
-              // Add tool message to conversation - ensure it's a string and include tool name
-              const resultString = typeof toolResult === 'string' ? toolResult : JSON.stringify(toolResult);
-              const toolMessage = new ToolMessage(resultString, toolCall.id, toolCall.name);
-              messages.push(toolMessage);
-              await this.memory.chatHistory.addMessage(toolMessage);
+              // Save tool interaction to memory (tool results will be included in next iteration's history)
+              await this.memory.saveContext(
+                { input: `Tool: ${toolCall.name}` },
+                { output: typeof toolResult === 'string' ? toolResult : JSON.stringify(toolResult) }
+              );
               
               consecutiveFailures = 0; // Reset on successful tool execution
             } catch (toolError) {
@@ -306,9 +486,11 @@ Example first call:
                 args: toolCall.args,
                 result: { error: errorMsg }
               });
-              const errorToolMessage = new ToolMessage(errorMsg, toolCall.id, toolCall.name);
-              messages.push(errorToolMessage);
-              await this.memory.chatHistory.addMessage(errorToolMessage);
+              // Save error to memory
+              await this.memory.saveContext(
+                { input: `Tool: ${toolCall.name}` },
+                { output: errorMsg }
+              );
               
               // Add context message after multiple failures by including it in the next system message
               if (consecutiveFailures >= 3) {
@@ -323,9 +505,11 @@ Example first call:
           console.log(`‚úÖ [AI_AGENT] Processing complete after ${iteration} iterations`);
           console.log(`Final response: ${result.content}`);
           
-          // Add final AI response to memory
-          const finalMessage = new AIMessage(result.content);
-          await this.memory.chatHistory.addMessage(finalMessage);
+          // Save final AI response to memory using v0.3 API
+          await this.memory.saveContext(
+            { input: currentUserMessage },
+            { output: result.content }
+          );
           
           return { 
             output: result.content,
@@ -335,19 +519,23 @@ Example first call:
           };
         }
         
-        // Add failure context to next iteration if needed
+        // Update current user message for next iteration if needed
         if (consecutiveFailures >= 3) {
-          const advisoryMessage = new HumanMessage(
-            `SYSTEM ADVISORY: ${consecutiveFailures} consecutive tool failures detected. Consider alternative approaches, verify tab context, or explain current limitations. Focus on recovery strategies.`
-          );
-          messages.push(advisoryMessage);
-          await this.memory.chatHistory.addMessage(advisoryMessage);
+          currentUserMessage = `SYSTEM ADVISORY: ${consecutiveFailures} consecutive tool failures detected. Consider alternative approaches, verify tab context, or explain current limitations. Focus on recovery strategies.`;
           consecutiveFailures = 0; // Reset after adding advisory
         }
         
-      } catch (error) {
-        console.error(`‚ùå [AI_AGENT] Error in iteration ${iteration}:`, error);
-        throw error;
+        } catch (error) {
+          console.error(`‚ùå [AI_AGENT] Error in iteration ${iteration}:`, error);
+          throw error;
+        }
+      }
+    } finally {
+      // Always restore original toolCall function
+      if (originalToolCall) {
+        this.toolCall = originalToolCall;
+      } else {
+        delete this.toolCall;
       }
     }
     
diff --git a/chrome/browser/resources/vibe/background.js b/chrome/browser/resources/vibe/background.js
index 38188aa9cf..83b3ff8db2 100644
--- a/chrome/browser/resources/vibe/background.js
+++ b/chrome/browser/resources/vibe/background.js
@@ -248,7 +248,7 @@ async function getAIConfiguration() {
       provider: provider,
       model: combined.model === 'auto' ? 'gpt-4o-mini' : (combined.model || 'gpt-4o-mini'),
       temperature: combined.temperature || 0.1,
-      maxTokens: combined.maxTokens || 1000,
+      maxTokens: combined.maxTokens || 128000,
       timeout: combined.agentTimeout || 30000,
       apiKeys: apiKeys,                    // All API keys by provider
       apiKey: activeApiKey,                // Active API key for backward compatibility
@@ -335,7 +335,7 @@ async function getBrowserSettingsViaMessage() {
         provider: vibePrefs['vibe_ai.provider'] || 'auto',
         model: vibePrefs['vibe_ai.model'] || 'gpt-4o-mini',
         temperature: vibePrefs['vibe_ai.temperature'] || 0.1,
-        maxTokens: vibePrefs['vibe_ai.max_tokens'] || 1000,
+        maxTokens: vibePrefs['vibe_ai.max_tokens'] || 128000,
         agentTimeout: vibePrefs['vibe_ai.agent_timeout'] || 30000,
         baseUrl: vibePrefs['vibe_ai.base_url'] || null,
         openaiApiKey: vibePrefs['vibe_ai.openai_api_key'] || null,
@@ -441,7 +441,10 @@ chrome.omnibox.onInputEntered.addListener(async (text, disposition) => {
     });
     
     // Process the query with AI agent
-    const aiResponse = await aiAgent.processQuery(text);
+    const aiResponse = await aiAgent.processUserRequest({
+      user_request: text,
+      tabId: activeTab.id
+    });
     
     // Send result to side panel
     await sendStatusUpdate(activeTab.id, {
-- 
2.50.0

